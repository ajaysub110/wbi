{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as opt\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/event_data.csv'\n",
    "MFF_DIR = '../data/'\n",
    "STIM_CHANNEL_NAMES = ['201' + str(i) for i in range(10)]\n",
    "EEG_CHANNEL_NAMES = ['E'+ str(i) for i in range(1,33)]\n",
    "FILE_ORDER = [\n",
    "    'ABI-Ashutosh-25-Sept-2019_20190925_102455.mff',\n",
    "    'ABI-Kartikeya-22-10-19_20191022_033359.mff',\n",
    "    'ABI-Kartikeya-22-10-19_20191022_040406.mff',\n",
    "    'ABI-Pranali-23-09-19_20190923_103745.mff',\n",
    "    'ABI-Shreyas-21-09-19_20190921_033411.mff',\n",
    "    'ABI2-Ashutosh-25-Sept-2019_20190925_104849.mff',\n",
    "    'ABI2-Pranali-23-Sept-19_20190923_110343.mff',\n",
    "    'ABI2-Shreyas-Sept-21_20190921_035826.mff',\n",
    "    'ABI2_Nishit_16Oct-2019_20191016_111224.mff',\n",
    "    'ABI_Nishit_16Oct-2019_20191016_104307.mff',  \n",
    "]\n",
    "EVENT_LENGTHS = [159] + [200]*9\n",
    "NUMPY_X_FNAME, NUMPY_Y_FNAME = MFF_DIR + 'X_small.npy',MFF_DIR + 'y_small.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### NO NEED TO RUN ###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.df = pd.read_csv(DATA_PATH)\n",
    "        self.current_file = None\n",
    "        self.current_raw = None\n",
    "        self.current_events = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.df.iloc[idx]['fname']\n",
    "        if self.current_file != fname or self.current_file is None:\n",
    "            self.current_file = fname\n",
    "            self.current_raw = mne.io.read_raw_egi(MFF_DIR + fname,verbose=False,preload=True).pick_channels(\n",
    "                STIM_CHANNEL_NAMES+EEG_CHANNEL_NAMES)\n",
    "            self.current_events = mne.find_events(self.current_raw,verbose=False)\n",
    "        s_time = self.df.iloc[idx]['s_time']/1000.0\n",
    "        if idx < 159:\n",
    "            fake_idx = idx\n",
    "        else:\n",
    "            fake_idx = (idx - 159)%200 \n",
    "        epoch = mne.Epochs(\n",
    "            self.current_raw.copy().pick_types(eeg=True),\n",
    "            self.current_events[fake_idx].reshape(1,-1),tmin=s_time,tmax=s_time+2.0-1.0/self.current_raw.info['sfreq'],\n",
    "            baseline=None,verbose=False)\n",
    "        # TODO: apply filter to eeg data\n",
    "        X = epoch.get_data()\n",
    "        y = self.df.iloc[idx]['label']\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset = EEGDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "i = 0\n",
    "for xi,yi in eeg_dataset:\n",
    "    if xi.shape == (1,32,2000):\n",
    "        print(i)\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.concatenate(X, axis=0)\n",
    "y_np = np.array(y)\n",
    "print(X_np.shape,y_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(NUMPY_X_FNAME,X_np)\n",
    "np.save(NUMPY_Y_FNAME,y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_np = np.load(NUMPY_X_FNAME)\n",
    "y_np = np.load(NUMPY_Y_FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch = torch.Tensor(X_np)\n",
    "y_torch = torch.Tensor(y_np)\n",
    "dset = TensorDataset(X_torch,y_torch) # create your datset\n",
    "dloader = DataLoader(dset,shuffle=True,batch_size=32) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([967, 32, 2000]) torch.Size([967])\n"
     ]
    }
   ],
   "source": [
    "print(X_torch.shape,y_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "class EEGEncoder(nn.Module):\n",
    "    def __init__(self, n_i):\n",
    "        super(EEGEncoder,self).__init__();\n",
    "        self.n_i = n_i\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(n_i, n_i, 1, bidirectional=False)\n",
    "        self.linear2 = nn.Linear(n_i, n_i)\n",
    "        self.linear3 = nn.Linear(n_i,n_i)\n",
    "        self.linear4 = nn.Linear(n_i,10)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return(autograd.Variable(torch.randn(1, batch_size, self.n_i)),\n",
    "                   autograd.Variable(torch.randn(1, batch_size, self.n_i)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.size(1))\n",
    "        self.hidden = self.init_hidden(x.size(1))\n",
    "        \n",
    "        x = x.reshape(2000,-1,32)\n",
    "        x, (hn,cn) = self.lstm1(x)\n",
    "        enc = self.linear2(hn)\n",
    "        x = F.relu(enc)\n",
    "        x = self.linear3(x)\n",
    "        x = self.linear4(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([1, 2, 10]) torch.Size([2000, 2, 32])\n"
     ]
    }
   ],
   "source": [
    "# Testing dimensions\n",
    "eeg_classifier = EEGEncoder(32)\n",
    "inp,l = torch.randn(2000,2,32),torch.randn(2)\n",
    "out = eeg_classifier(inp)\n",
    "print(out.shape, inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = opt.Adam(eeg_classifier.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "[1/1]: loss = 0.04600159168243408\n",
      "32\n",
      "[1/2]: loss = 0.046103897094726565\n",
      "32\n",
      "[1/3]: loss = 0.04605252265930176\n",
      "32\n",
      "[1/4]: loss = 0.04604339599609375\n",
      "32\n",
      "[1/5]: loss = 0.046080403327941895\n",
      "32\n",
      "[1/6]: loss = 0.04599217414855957\n",
      "32\n",
      "[1/7]: loss = 0.04601802349090576\n",
      "32\n",
      "[1/8]: loss = 0.04602993965148926\n",
      "32\n",
      "[1/9]: loss = 0.04608822345733642\n",
      "32\n",
      "[1/10]: loss = 0.046108460426330565\n",
      "32\n",
      "[1/11]: loss = 0.04607489585876465\n",
      "32\n",
      "[1/12]: loss = 0.04601302146911621\n",
      "32\n",
      "[1/13]: loss = 0.04602396965026855\n",
      "32\n",
      "[1/14]: loss = 0.04605020046234131\n",
      "32\n",
      "[1/15]: loss = 0.045997314453125\n",
      "32\n",
      "[1/16]: loss = 0.04612736701965332\n",
      "32\n",
      "[1/17]: loss = 0.04599282741546631\n",
      "32\n",
      "[1/18]: loss = 0.04607442378997803\n",
      "32\n",
      "[1/19]: loss = 0.04600024223327637\n",
      "32\n",
      "[1/20]: loss = 0.046154084205627444\n",
      "32\n",
      "[1/21]: loss = 0.046015629768371584\n",
      "32\n",
      "[1/22]: loss = 0.04603672981262207\n",
      "32\n",
      "[1/23]: loss = 0.04596701622009278\n",
      "32\n",
      "[1/24]: loss = 0.04607097625732422\n",
      "32\n",
      "[1/25]: loss = 0.045994539260864255\n",
      "32\n",
      "[1/26]: loss = 0.04603262424468994\n",
      "32\n",
      "[1/27]: loss = 0.04604990005493164\n",
      "32\n",
      "[1/28]: loss = 0.04596572399139404\n",
      "32\n",
      "[1/29]: loss = 0.046031436920166015\n",
      "32\n",
      "[1/30]: loss = 0.04603986740112305\n",
      "32\n",
      "[1/31]: loss = 0.04606422424316406\n",
      "32\n",
      "[2/1]: loss = 0.04596728801727295\n",
      "32\n",
      "[2/2]: loss = 0.04599454879760742\n",
      "32\n",
      "[2/3]: loss = 0.04592047214508057\n",
      "32\n",
      "[2/4]: loss = 0.04599836826324463\n",
      "32\n",
      "[2/5]: loss = 0.046021676063537596\n",
      "32\n",
      "[2/6]: loss = 0.04604527473449707\n",
      "32\n",
      "[2/7]: loss = 0.046024417877197264\n",
      "32\n",
      "[2/8]: loss = 0.04615160465240478\n",
      "32\n",
      "[2/9]: loss = 0.046017026901245116\n",
      "32\n",
      "[2/10]: loss = 0.04595822811126709\n",
      "32\n",
      "[2/11]: loss = 0.0459845495223999\n",
      "32\n",
      "[2/12]: loss = 0.04599352359771729\n",
      "32\n",
      "[2/13]: loss = 0.04596363067626953\n",
      "32\n",
      "[2/14]: loss = 0.04601704120635986\n",
      "32\n",
      "[2/15]: loss = 0.04603130340576172\n",
      "32\n",
      "[2/16]: loss = 0.046089158058166504\n",
      "32\n",
      "[2/17]: loss = 0.04604060173034668\n",
      "32\n",
      "[2/18]: loss = 0.046093316078186036\n",
      "32\n",
      "[2/19]: loss = 0.04604675769805908\n",
      "32\n",
      "[2/20]: loss = 0.046119070053100585\n",
      "32\n",
      "[2/21]: loss = 0.046087918281555174\n",
      "32\n",
      "[2/22]: loss = 0.04600631713867188\n",
      "32\n",
      "[2/23]: loss = 0.046121830940246585\n",
      "32\n",
      "[2/24]: loss = 0.04609917640686035\n",
      "32\n",
      "[2/25]: loss = 0.045905079841613766\n",
      "32\n",
      "[2/26]: loss = 0.046091837882995604\n",
      "32\n",
      "[2/27]: loss = 0.04611881732940674\n",
      "32\n",
      "[2/28]: loss = 0.04603315830230713\n",
      "32\n",
      "[2/29]: loss = 0.04604154109954834\n",
      "32\n",
      "[2/30]: loss = 0.0459259033203125\n",
      "32\n",
      "[2/31]: loss = 0.04610612392425537\n",
      "32\n",
      "[3/1]: loss = 0.046039824485778806\n",
      "32\n",
      "[3/2]: loss = 0.04612016677856445\n",
      "32\n",
      "[3/3]: loss = 0.04612798690795898\n",
      "32\n",
      "[3/4]: loss = 0.04604637145996094\n",
      "32\n",
      "[3/5]: loss = 0.04605765819549561\n",
      "32\n",
      "[3/6]: loss = 0.04604942798614502\n",
      "32\n",
      "[3/7]: loss = 0.046004233360290525\n",
      "32\n",
      "[3/8]: loss = 0.046049609184265136\n",
      "32\n",
      "[3/9]: loss = 0.046271963119506834\n",
      "32\n",
      "[3/10]: loss = 0.04601519107818604\n",
      "32\n",
      "[3/11]: loss = 0.04589476585388184\n",
      "32\n",
      "[3/12]: loss = 0.04599119663238525\n",
      "32\n",
      "[3/13]: loss = 0.045965538024902344\n",
      "32\n",
      "[3/14]: loss = 0.045967483520507814\n",
      "32\n",
      "[3/15]: loss = 0.04613147735595703\n",
      "32\n",
      "[3/16]: loss = 0.04599953174591064\n",
      "32\n",
      "[3/17]: loss = 0.04597572326660156\n",
      "32\n",
      "[3/18]: loss = 0.04591845989227295\n",
      "32\n",
      "[3/19]: loss = 0.04617498397827149\n",
      "32\n",
      "[3/20]: loss = 0.04596358299255371\n",
      "32\n",
      "[3/21]: loss = 0.04572938442230225\n",
      "32\n",
      "[3/22]: loss = 0.04591086387634277\n",
      "32\n",
      "[3/23]: loss = 0.0459940242767334\n",
      "32\n",
      "[3/24]: loss = 0.0459993314743042\n",
      "32\n",
      "[3/25]: loss = 0.04608024597167969\n",
      "32\n",
      "[3/26]: loss = 0.04604496955871582\n",
      "32\n",
      "[3/27]: loss = 0.0460603666305542\n",
      "32\n",
      "[3/28]: loss = 0.045996999740600585\n",
      "32\n",
      "[3/29]: loss = 0.046018385887146\n",
      "32\n",
      "[3/30]: loss = 0.04604525566101074\n",
      "32\n",
      "[3/31]: loss = 0.04552684783935547\n",
      "32\n",
      "[4/1]: loss = 0.04613188266754151\n",
      "32\n",
      "[4/2]: loss = 0.046128463745117185\n",
      "32\n",
      "[4/3]: loss = 0.046020798683166504\n",
      "32\n",
      "[4/4]: loss = 0.04616650104522705\n",
      "32\n",
      "[4/5]: loss = 0.04600780487060547\n",
      "32\n",
      "[4/6]: loss = 0.04610905170440674\n",
      "32\n",
      "[4/7]: loss = 0.04608114719390869\n",
      "32\n",
      "[4/8]: loss = 0.04599871635437012\n",
      "32\n",
      "[4/9]: loss = 0.046058120727539065\n",
      "32\n",
      "[4/10]: loss = 0.04591357707977295\n",
      "32\n",
      "[4/11]: loss = 0.046147971153259276\n",
      "32\n",
      "[4/12]: loss = 0.04597038269042969\n",
      "32\n",
      "[4/13]: loss = 0.04587270259857178\n",
      "32\n",
      "[4/14]: loss = 0.046004023551940915\n",
      "32\n",
      "[4/15]: loss = 0.04584972381591797\n",
      "32\n",
      "[4/16]: loss = 0.04602750301361084\n",
      "32\n",
      "[4/17]: loss = 0.04581788539886475\n",
      "32\n",
      "[4/18]: loss = 0.0460633659362793\n",
      "32\n",
      "[4/19]: loss = 0.046069369316101075\n",
      "32\n",
      "[4/20]: loss = 0.04592362880706787\n",
      "32\n",
      "[4/21]: loss = 0.04585108757019043\n",
      "32\n",
      "[4/22]: loss = 0.04591868400573731\n",
      "32\n",
      "[4/23]: loss = 0.04590962409973145\n",
      "32\n",
      "[4/24]: loss = 0.045776772499084475\n",
      "32\n",
      "[4/25]: loss = 0.04612400531768799\n",
      "32\n",
      "[4/26]: loss = 0.04620459079742432\n",
      "32\n",
      "[4/27]: loss = 0.04603044033050537\n",
      "32\n",
      "[4/28]: loss = 0.046109066009521485\n",
      "32\n",
      "[4/29]: loss = 0.04596852302551269\n",
      "32\n",
      "[4/30]: loss = 0.04565445899963379\n",
      "32\n",
      "[4/31]: loss = 0.04585960865020752\n",
      "32\n",
      "[5/1]: loss = 0.04602150917053223\n",
      "32\n",
      "[5/2]: loss = 0.04566123485565186\n",
      "32\n",
      "[5/3]: loss = 0.04629296779632568\n",
      "32\n",
      "[5/4]: loss = 0.04581568717956543\n",
      "32\n",
      "[5/5]: loss = 0.0460978889465332\n",
      "32\n",
      "[5/6]: loss = 0.04594907760620117\n",
      "32\n",
      "[5/7]: loss = 0.04578932285308838\n",
      "32\n",
      "[5/8]: loss = 0.046287951469421384\n",
      "32\n",
      "[5/9]: loss = 0.04548912048339844\n",
      "32\n",
      "[5/10]: loss = 0.04609094142913819\n",
      "32\n",
      "[5/11]: loss = 0.04576782703399658\n",
      "32\n",
      "[5/12]: loss = 0.04609667301177978\n",
      "32\n",
      "[5/13]: loss = 0.04584937572479248\n",
      "32\n",
      "[5/14]: loss = 0.04605170726776123\n",
      "32\n",
      "[5/15]: loss = 0.04601649284362793\n",
      "32\n",
      "[5/16]: loss = 0.04586704254150391\n",
      "32\n",
      "[5/17]: loss = 0.04621788024902344\n",
      "32\n",
      "[5/18]: loss = 0.045826802253723146\n",
      "32\n",
      "[5/19]: loss = 0.04587045192718506\n",
      "32\n",
      "[5/20]: loss = 0.04632742404937744\n",
      "32\n",
      "[5/21]: loss = 0.04569265365600586\n",
      "32\n",
      "[5/22]: loss = 0.046505093574523926\n",
      "32\n",
      "[5/23]: loss = 0.046005630493164064\n",
      "32\n",
      "[5/24]: loss = 0.04607378959655762\n",
      "32\n",
      "[5/25]: loss = 0.0462130069732666\n",
      "32\n",
      "[5/26]: loss = 0.04558121681213379\n",
      "32\n",
      "[5/27]: loss = 0.046029911041259766\n",
      "32\n",
      "[5/28]: loss = 0.04564671516418457\n",
      "32\n",
      "[5/29]: loss = 0.04636118888854981\n",
      "32\n",
      "[5/30]: loss = 0.04570127964019775\n",
      "32\n",
      "[5/31]: loss = 0.04632386207580566\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in enumerate(dloader,0):\n",
    "        inp,lab = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        out = eeg_classifier(inp)\n",
    "        out = out.reshape(-1,10)\n",
    "                        \n",
    "        loss = criterion(out.float(),lab.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 1 == 0:\n",
    "            print('[{}/{}]: loss = {}'.format(epoch+1,i+1,running_loss/50))\n",
    "            losses.append(running_loss/50)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([7., 1., 0., 5., 3., 7., 6., 6., 0., 2., 4., 9., 0., 0., 7., 6., 2., 1.,\n",
      "        8., 5., 8., 5., 2., 7., 7., 9., 0., 4., 0., 0., 8., 5.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([4., 2., 9., 4., 8., 0., 8., 6., 4., 5., 7., 2., 8., 2., 2., 2., 1., 4.,\n",
      "        5., 9., 2., 8., 9., 2., 0., 1., 3., 8., 3., 7., 7., 7.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([5., 4., 2., 4., 8., 3., 0., 5., 6., 6., 3., 9., 2., 4., 7., 3., 2., 9.,\n",
      "        4., 9., 2., 5., 3., 2., 3., 1., 0., 9., 2., 3., 6., 6.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([0., 5., 0., 8., 3., 2., 5., 2., 1., 2., 0., 2., 8., 5., 6., 0., 1., 8.,\n",
      "        3., 2., 6., 3., 4., 5., 8., 8., 3., 9., 8., 4., 6., 8.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([9., 7., 3., 1., 3., 3., 2., 0., 2., 6., 4., 1., 2., 2., 9., 3., 0., 2.,\n",
      "        3., 4., 9., 6., 5., 3., 6., 0., 1., 4., 1., 7., 2., 4.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([4., 0., 1., 3., 2., 8., 3., 7., 4., 1., 8., 5., 5., 6., 3., 9., 7., 9.,\n",
      "        1., 5., 6., 4., 1., 1., 2., 1., 3., 2., 3., 0., 4., 8.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([5., 6., 9., 9., 2., 7., 3., 6., 3., 4., 6., 6., 2., 4., 7., 9., 2., 5.,\n",
      "        9., 7., 9., 5., 5., 4., 7., 3., 6., 1., 9., 0., 6., 9.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([7., 1., 2., 2., 0., 8., 4., 1., 1., 2., 0., 9., 2., 6., 9., 8., 2., 6.,\n",
      "        2., 7., 1., 5., 7., 7., 7., 6., 3., 8., 5., 4., 3., 9.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([2., 6., 3., 7., 3., 9., 0., 7., 7., 9., 0., 6., 0., 1., 7., 0., 9., 8.,\n",
      "        8., 0., 7., 3., 0., 8., 9., 0., 5., 8., 1., 8., 1., 3.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([4., 7., 2., 1., 9., 3., 1., 7., 3., 4., 8., 9., 9., 0., 2., 5., 3., 6.,\n",
      "        9., 8., 1., 1., 7., 8., 1., 3., 6., 9., 6., 9., 5., 3.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([1., 0., 7., 5., 7., 7., 9., 6., 4., 5., 1., 5., 9., 9., 0., 8., 1., 2.,\n",
      "        5., 7., 0., 6., 7., 6., 8., 5., 0., 7., 9., 3., 9., 1.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([9., 3., 6., 1., 1., 3., 0., 7., 7., 9., 6., 6., 0., 3., 3., 3., 6., 7.,\n",
      "        5., 0., 6., 0., 3., 4., 6., 6., 8., 4., 9., 5., 5., 6.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([8., 7., 2., 3., 8., 6., 7., 8., 2., 6., 8., 4., 5., 6., 2., 2., 2., 7.,\n",
      "        5., 5., 8., 8., 5., 0., 1., 5., 4., 6., 2., 8., 2., 9.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([0., 4., 9., 6., 9., 6., 8., 6., 1., 7., 4., 2., 5., 9., 0., 3., 7., 9.,\n",
      "        4., 4., 2., 0., 7., 5., 1., 2., 7., 0., 8., 4., 8., 8.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 8., 2., 8., 0., 2., 7., 8., 7., 0., 2., 3., 7., 8., 4., 5., 5., 1.,\n",
      "        8., 2., 9., 3., 0., 2., 7., 2., 3., 6., 9., 9., 6., 7.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([3., 3., 0., 5., 5., 4., 0., 6., 1., 7., 0., 9., 9., 3., 9., 9., 8., 5.,\n",
      "        8., 3., 5., 0., 4., 1., 1., 9., 1., 0., 0., 6., 2., 4.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 9., 7., 9., 9., 9., 7., 7., 8., 9., 5., 4., 1., 2., 1., 3., 5., 7.,\n",
      "        0., 9., 1., 1., 8., 8., 6., 9., 7., 4., 5., 2., 5., 4.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([5., 8., 1., 6., 1., 2., 7., 1., 6., 2., 1., 4., 8., 0., 2., 8., 4., 3.,\n",
      "        2., 1., 6., 6., 3., 1., 5., 6., 9., 9., 8., 8., 6., 5.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([9., 9., 8., 6., 0., 3., 2., 1., 1., 9., 0., 9., 2., 3., 0., 2., 0., 3.,\n",
      "        9., 1., 3., 3., 7., 2., 1., 2., 5., 9., 0., 7., 7., 6.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 0., 2., 2., 0., 2., 5., 7., 1., 7., 3., 5., 9., 5., 3., 2., 9., 6.,\n",
      "        0., 7., 6., 6., 2., 2., 3., 4., 9., 3., 2., 8., 3., 2.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([9., 3., 8., 7., 5., 6., 3., 2., 3., 1., 3., 0., 3., 5., 0., 4., 5., 5.,\n",
      "        1., 2., 8., 6., 1., 5., 7., 4., 0., 3., 9., 9., 8., 1.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([8., 1., 5., 4., 1., 6., 2., 4., 8., 7., 0., 3., 0., 1., 0., 5., 6., 3.,\n",
      "        3., 7., 8., 4., 7., 5., 8., 3., 9., 9., 6., 3., 8., 3.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([4., 2., 6., 7., 1., 9., 3., 9., 1., 9., 2., 5., 4., 6., 3., 8., 4., 6.,\n",
      "        4., 3., 7., 3., 5., 9., 4., 7., 7., 7., 4., 7., 4., 6.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 2., 2., 7., 7., 8., 7., 7., 5., 6., 5., 1., 2., 3., 7., 5., 5., 1.,\n",
      "        3., 6., 3., 8., 2., 4., 9., 3., 7., 1., 9., 5., 2., 1.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 9., 2., 7., 5., 8., 3., 6., 6., 5., 8., 8., 8., 3., 6., 5., 1., 8.,\n",
      "        3., 0., 5., 5., 1., 8., 5., 7., 1., 5., 8., 7., 5., 3.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([4., 8., 0., 5., 8., 1., 1., 2., 4., 2., 7., 9., 0., 8., 4., 9., 8., 8.,\n",
      "        0., 9., 2., 4., 7., 0., 5., 1., 5., 6., 4., 7., 5., 1.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 0., 6., 7., 5., 6., 6., 2., 2., 6., 9., 8., 4., 0., 8., 6., 8., 3.,\n",
      "        6., 2., 3., 3., 3., 9., 3., 0., 8., 4., 7., 5., 4., 7.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([6., 6., 0., 9., 2., 5., 3., 4., 6., 3., 2., 1., 7., 6., 8., 4., 4., 7.,\n",
      "        5., 7., 9., 3., 3., 3., 4., 1., 2., 3., 2., 7., 0., 5.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([9., 0., 4., 2., 6., 3., 6., 3., 6., 3., 7., 2., 2., 7., 2., 7., 9., 0.,\n",
      "        2., 3., 0., 1., 0., 9., 3., 3., 4., 7., 9., 1., 7., 9.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3]]) tensor([7., 0., 9., 7., 9., 2., 4., 8., 7., 1., 5., 9., 5., 9., 2., 3., 7., 2.,\n",
      "        7., 2., 9., 5., 4., 7., 9., 4., 9., 4., 6., 3., 2., 3.])\n",
      "32\n",
      "tensor([[3, 3, 3, 3, 3, 3, 3]]) tensor([4., 7., 3., 4., 1., 3., 1.])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dloader,0):\n",
    "        inp,lab = data\n",
    "        out = eeg_classifier(inp);\n",
    "        print(out.argmax(dim=2),lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
